<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Stochastic Processes & Finance â€“ Summer Reading Project</title>
  <link href="https://fonts.googleapis.com/css2?family=Lato&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Lato', sans-serif;
      margin: 0;
      padding: 0;
      background: #f9f9f9;
      color: #333;
    }
    header {
      background-color: #003366;
      color: white;
      padding: 1em;
      text-align: center;
    }
    nav {
      background-color: #e0e0e0;
      padding: 1em;
      text-align: center;
    }
    nav a {
      margin: 0 1em;
      text-decoration: none;
      color: #003366;
      font-weight: bold;
    }
    section {
      max-width: 1200px;
      margin: 2em auto;
      padding: 1em;
      background: white;
      border-radius: 8px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }

    .nav-bottom a {
      flex: 1;
      text-align: center;
      padding: 0.5em 1em;
      color: #003366;
      font-weight: bold;
      text-decoration: none;
    }

    footer {
      text-align: center;
      font-size: 0.9em;
      color: #777;
      margin: 2em 0;
    }
    .hint-text {
      display: none;
      margin-top: 0.5em;
      background: #f0f0f0;
      padding: 0.5em;
      border-left: 4px solid #0077cc;
      border-radius: 4px;
    }

    .hint-button {
      margin-top: 1em;
      background-color: #0077cc;
      color: white;
      border: none;
      padding: 0.4em 0.8em;
      border-radius: 4px;
      cursor: pointer;
      font-size: 0.9em;
    }

    .hint-button:hover {
      background-color: #005fa3;
    }
  </style>
</head>
<body>

<header>
  <h1>Chapter 2: Markov Chains: Introduction</h1>
  <p>Study notes and chapter summaries</p>
</header>

<nav>
  <a href="index.html">Home</a>
  <a href="topics.html">Topics</a>
  <a href="notes.html">Notes</a>
  <a href="projects.html">Programming</a>
</nav>
<section>
<h2>1. Definition</h2>
<p>
  A Markov process \(X_t\) is a stochastic process with the property that, given the value of \(X_t\), the values of \(X_s\) for s>t are not influenced by the values of \(X_u\)  for \(t> u\).  
</p>
<p>
  A discrete-time Markov chain is a Markov process whose state space is a finite or countable set, and whose (time) index set is T =\( (0,1,2 \ldots ) \). Mathematically:
  $$ P(X_{n+1} = j| X_0 = i_0, \ldots , X_{n-1} = i_{n-1}, X_n= i) $$
  $$ = P( X_{n+1} =j | X_n= i) $$
  for all n and all states \( i_0 , \ldots, i_{n-1}, i, j \)
</p>
<h3>Understanding One-Step Transition Probabilities</h3>
<p>
In a Markov chain, we usually label the state space using non-negative integers: 
<strong>0, 1, 2, ...</strong>. Unless stated otherwise, we follow this convention.
</p>
<p>
If the chain is in a certain state at time \( n \), we say \( X_n = i \).
The probability that it moves to state \( j \) at the next time step \( n+1 \),
given that it is currently in state \( i \), is called the 
<strong>one-step transition probability</strong>. It is denoted by:
</p>
\[
P^{(n,n+1)}_{ij} = \Pr(X_{n+1} = j \mid X_n = i)
\]
<p>
This notation indicates that the transition probabilities can depend on the current time \( n \),
as well as the current and next states \( i \) and \( j \).
</p>
<p>
If these probabilities are independent of time, we say that the Markov chain has 
<strong>stationary transition probabilities</strong>. In that case, we write:
</p>
\[
P_{ij} = \Pr(X_{n+1} = j \mid X_n = i)
\]
<p>
This means the probability of transitioning from state \( i \) to state \( j \)
remains the same at every step.
</p>
<p>
These probabilities \( P_{ij} \) are usually arranged in a 
<strong>transition matrix</strong> \( P \) as follows:
</p>
\[
P = 
\begin{bmatrix}
P_{00} & P_{01} & P_{02} & \cdots \\
P_{10} & P_{11} & P_{12} & \cdots \\
P_{20} & P_{21} & P_{22} & \cdots \\
\vdots & \vdots & \vdots & \ddots \\
\end{bmatrix}
\]
<p>
Each row corresponds to the current state \( i \), and each column represents the
probability of transitioning to state \( j \).
</p>
























<p><strong>Last updated:</strong> May 15, 2025</p>
</section>

<div class="nav-bottom">
  <a href="tk-intro.html">Prev Chapter &larr;</a>
  <a href="tk-markov-chains2.html">Next Chapter &rarr;</a>
</div>

<footer>
  &copy; 2025 Mohammad Shaan | This site is maintained on GitHub Pages.
</footer>
<!-- MathJax for LaTeX -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<script>
  function toggleHint(id) {
    var hint = document.getElementById(id);
    if (hint.style.display === "none" || hint.style.display === "") {
      hint.style.display = "block";
    } else {
      hint.style.display = "none";
    }
  }
</script>

</body>
</html>
